import os
import time
import requests
import re
import textwrap
import random
import gc
import json
from moviepy.editor import (
    TextClip, ImageClip, CompositeVideoClip, ColorClip,
    concatenate_videoclips, AudioFileClip, CompositeAudioClip
)
from moviepy.config import change_settings

# í™˜ê²½ ì„¤ì •
change_settings({"IMAGEMAGICK_BINARY": "C:\\Program Files\\ImageMagick-7.1.1-Q16-HDRI\\magick.exe"})
font_path = "C:/Windows/Fonts/HANSomaB.ttf"
WIDTH, HEIGHT = 1080, 1920
PIXABAY_API_KEY = "30559987-df2ee55eeb0cdbaef8ad520a5"
BGM_FOLDER = "C:/music/bgm"

# ìœ í‹¸
def ensure_folder(path): os.makedirs(path, exist_ok=True)
def sanitize_filename(name): return re.sub(r'[\\/*?:"<>|]', "", name)
def wrap_text(text, width=20): return "\n".join(textwrap.wrap(text, width=width))
def split_sentences(text): return [s.strip() for s in re.split(r'[,.?!]\s+', text) if s.strip()]
def extract_keyword(sentence): return sentence.split()[0] if sentence else "ë°°ê²½"

# Pixabay ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ì˜¤ë¥˜ ì²˜ë¦¬ ì¶”ê°€)
def download_pixabay_image(search_query, api_key, save_path="default.jpg"):
    base_url = "https://pixabay.com/api/"
    params = {
        "key": api_key,
        "q": search_query,
        "image_type": "photo",
        "orientation": "vertical",
        "safesearch": "true",
        "per_page": 3,
        "lang": "ko"
    }
    response = requests.get(base_url, params=params)

    try:
        data = response.json()
    except requests.exceptions.JSONDecodeError:
        print("âŒ JSON ë””ì½”ë”© ì‹¤íŒ¨ (ì‘ë‹µ ë‚´ìš©ì´ ë¹„ì–´ìˆê±°ë‚˜ JSON ì•„ë‹˜)")
        print(f"ìƒíƒœ ì½”ë“œ: {response.status_code}")
        print(f"ì‘ë‹µ ë³¸ë¬¸: {response.text}")
        return None

    if "hits" in data and len(data["hits"]) > 0:
        image_url = data["hits"][0]["largeImageURL"]
        image_data = requests.get(image_url).content
        with open(save_path, "wb") as f:
            f.write(image_data)
        print(f"âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_path}")
        return save_path
    else:
        print("âŒ ì´ë¯¸ì§€ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ.")
        return None

# Typecast TTS
API_TOKEN = "__plt4tj3EcRdrNaiX6vjui6k6Ycz4DQK8ioC3kCsoS5q"
ACTOR_ID = "5ecbbc7399979700087711db"
HEADERS = {
    'Content-Type': 'application/json',
    'Authorization': f'Bearer {API_TOKEN}'
}

def generate_tts_typecast(text, index):
    print(f"TTS ìš”ì²­ ì¤‘ì…ë‹ˆë‹¤... {text[:25]}")
    payload = {
        "actor_id": ACTOR_ID,
        "text": text,
        "lang": "auto",
        "tempo": 1,
        "volume": 100,
        "pitch": 0,
        "xapi_hd": True,
        "max_seconds": 60,
        "model_version": "latest",
        "xapi_audio_format": "wav"
    }

    try:
        response = requests.post("https://typecast.ai/api/speak", headers=HEADERS, data=json.dumps(payload))
        response.raise_for_status()
    except Exception as e:
        print(f"âŒ Typecast ìš”ì²­ ì˜¤ë¥˜: {e}")
        try:
            print(f"ì‘ë‹µ: {response.text}")
        except:
            print("ì‘ë‹µ ë³¸ë¬¸ì„ ì¶œë ¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        raise Exception("TTS ìš”ì²­ ì‹¤íŒ¨")

    result = response.json().get("result", {})
    speak_url = result.get("speak_v2_url")
    if not speak_url:
        raise Exception("TTS ì‘ë‹µ ì˜¤ë¥˜: speak_v2_url ì—†ìŒ")

    for _ in range(60):
        poll = requests.get(speak_url, headers=HEADERS)
        poll_data = poll.json().get("result", {})
        status = poll_data.get("status")
        if status == "done":
            audio_url = poll_data.get("audio_download_url")
            break
        elif status == "fail":
            raise Exception("TTS ìƒì„± ì‹¤íŒ¨")
        time.sleep(1)
    else:
        raise Exception("TTS íƒ€ì„ì•„ì›ƒ")

    if not audio_url:
        raise Exception("TTS ì˜¤ë””ì˜¤ URL ì—†ìŒ")

    output_path = f"tts_{index}.wav"
    audio_response = requests.get(audio_url)
    with open(output_path, "wb") as f:
        f.write(audio_response.content)

    print(f"âœ… TTS ì €ì¥ ì™„ë£Œ: {output_path}")
    return output_path

# ì´ë¯¸ì§€ íš¨ê³¼
def apply_random_effect(image_clip, duration):
    effect_type = random.choice(["zoom_in", "zoom_out", "pan_left", "pan_right", "static"])
    if effect_type == "zoom_in":
        return image_clip.resize(lambda t: 1 + 0.05 * t).set_duration(duration)
    elif effect_type == "zoom_out":
        return image_clip.resize(lambda t: 1.2 - 0.05 * t).set_duration(duration)
    elif effect_type == "pan_left":
        return image_clip.set_position(lambda t: (-50 + 50 * t / duration, 0)).set_duration(duration)
    elif effect_type == "pan_right":
        return image_clip.set_position(lambda t: (50 - 50 * t / duration, 0)).set_duration(duration)
    else:
        return image_clip.set_duration(duration)

# ìŠ¬ë¼ì´ë“œ ìƒì„±
def create_slide(text, image_path, font_path=font_path, duration=5, index=0):
    img_clip = apply_random_effect(ImageClip(image_path).resize((WIDTH, HEIGHT)), duration)
    txt = TextClip(
        wrap_text(text),
        fontsize=90,
        font=font_path,
        color='white',
        stroke_color='black',
        stroke_width=3,
        method='caption',
        size=(WIDTH - 200, None),
        align='center'
    ).set_duration(duration)

    bar_height = txt.size[1] + 40
    bar = ColorClip((WIDTH, bar_height), color=(0, 0, 0)).set_opacity(0.0).set_duration(duration)
    txt = txt.set_position(("center", HEIGHT - bar_height - 80))
    bar = bar.set_position(("center", HEIGHT - bar_height - 80))

    tts_path = generate_tts_typecast(text, index)
    audio_clip = AudioFileClip(tts_path)

    video = CompositeVideoClip([img_clip, bar, txt]).set_audio(audio_clip).set_duration(audio_clip.duration)
    return video, tts_path

# ì „í™˜ íš¨ê³¼
def apply_transition(prev_clip, next_clip, transition_type):
    if transition_type == "crossfade":
        return prev_clip.crossfadeout(1), next_clip.crossfadein(1)
    elif transition_type == "fadeinout":
        return prev_clip.fadeout(1), next_clip.fadein(1)
    elif transition_type == "slide_right":
        next_slide = next_clip.set_start(prev_clip.duration - 1).set_position(lambda t: ('center', HEIGHT - t * 100))
        return prev_clip, next_slide
    elif transition_type == "slide_bottom":
        next_slide = next_clip.set_start(prev_clip.duration - 1).set_position(lambda t: ('center', HEIGHT + 50 - t * 200))
        return prev_clip, next_slide
    else:
        return prev_clip, next_clip

# ë°°ê²½ìŒì•…
def get_random_bgm():
    if not os.path.exists(BGM_FOLDER): return None
    files = [f for f in os.listdir(BGM_FOLDER) if f.lower().endswith(('.mp3', '.wav'))]
    if not files: return None
    bgm_path = os.path.join(BGM_FOLDER, random.choice(files))
    print(f"ğŸ¶ ë°°ê²½ìŒì•… ì‚½ì…: {os.path.basename(bgm_path)}")
    return AudioFileClip(bgm_path)

# ë©”ì¸ ì‹¤í–‰
def main():
    input_text = """
    AIê°€ ì¼ìë¦¬ë¥¼ ëºëŠ”ë‹¤. ì´ì œëŠ” ì§„ì§œ ê¸°ìˆ ì´ í•„ìš”. ê¸°ìˆ  ì—†ëŠ” ë°±ìˆ˜ëŠ” ìœ„í—˜. ê·¸ì¤‘ ê°€ì¥ ë¨¼ì € ë¬´ë„ˆì§„ ê³³. ë°”ë¡œ ì½”ë”© í•™ì›ì´ì•¼. ì½”ë”© í•™ì›ì´ ì™œ ë§í–ˆëƒê³ ? ìˆ˜ê°•ìƒì´ ë‹¤ ë–¨ì–´ì ¸ ë‚˜ê°€. AIê°€ ì½”ë”©ê¹Œì§€ í•˜ê±°ë“ . ê·¼ë° ì§„ì§œ ì›ƒê¸´ ê±´ ë­”ì§€? ê·¸ë˜ë„ ì½”ë”©ì€ í•„ìˆ˜ì•¼. AIë„ ê²°êµ­ ì½”ë”©ì˜ ì‚°ë¬¼. ê¸°ì´ˆëŠ” ì•Œì•„ì•¼ ëŒ€ì‘ë¼. ì•„ì˜ˆ ëª»í•˜ë©´ ì§„ì§œ ëì´ì•¼. ì½”ë”©ì€ í˜„ëŒ€ì˜ ê¸€ì“°ê¸°. ì•ˆ í•˜ë©´ ë¬´ê¸° ì—†ì´ ì „ìŸ. ì½”ë”© ëª°ë¼ë„ ëë˜ ì‹œëŒ€. ì´ì œëŠ” ë‹¤ì‹œ ì•ˆ ì™€. ë¨¸ë­‡ëŒ€ë©´ ëŠ¦ì–´. ì§€ê¸ˆë¶€í„°ë¼ë„ ì‹œì‘í•´. ì½”ë”©, ê¼­ ë°°ì›Œì•¼ í•´.
    """
    sentences = split_sentences(input_text)
    slides, tts_paths = [], []

    for i, sentence in enumerate(sentences):
        keyword = extract_keyword(sentence)
        img_path = f"bg_{i}.jpg"
        if download_pixabay_image(keyword, PIXABAY_API_KEY, img_path):
            clip, tts_path = create_slide(sentence, img_path, index=i)
            slides.append(clip)
            tts_paths.append(tts_path)

    if not slides:
        print("âš ï¸ ìŠ¬ë¼ì´ë“œ ìƒì„± ì‹¤íŒ¨")
        return

    # ì „í™˜ ì ìš©
    final_clips = []
    for i in range(len(slides) - 1):
        transition = random.choice(["crossfade", "fadeinout", "slide_right", "slide_bottom", "none"])
        a, b = apply_transition(slides[i], slides[i + 1], transition)
        final_clips.append(a)
        if transition != "none": b = b.set_start(a.end)
        final_clips.append(b)

    if len(slides) == 1:
        final_clips = slides
    elif len(final_clips) < len(slides):
        final_clips.append(slides[-1])

    final_video = concatenate_videoclips(final_clips, method="compose")

    # ë°°ê²½ìŒì•… ì¶”ê°€
    bgm = get_random_bgm()
    if bgm:
        bgm = bgm.volumex(0.2).set_duration(final_video.duration)
        final_video = final_video.set_audio(CompositeAudioClip([final_video.audio, bgm]))

    # ì €ì¥
    save_path = "C:/shortsClip"
    ensure_folder(save_path)
    filename = sanitize_filename(sentences[0][:20]) + ".mp4"
    output = os.path.join(save_path, filename)
    final_video.write_videofile(output, fps=24)

    # ì •ë¦¬ ë§Œë“ íŒŒì¼ ì§€ìš°ê¸°
    # for f in tts_paths:
    #     try: os.remove(f)
    #     except: pass

    print(f"ğŸ‰ ì˜ìƒ ì €ì¥ ì™„ë£Œ: {output}")

if __name__ == "__main__":
    main()
