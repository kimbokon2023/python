import os
import re
import textwrap
import requests
import random
import pyttsx3
import gc
from moviepy.editor import (
    TextClip, ImageClip, CompositeVideoClip, ColorClip,
    concatenate_videoclips, AudioFileClip, CompositeAudioClip
)
from moviepy.config import change_settings

change_settings({"IMAGEMAGICK_BINARY": "C:\\Program Files\\ImageMagick-7.1.1-Q16-HDRI\\magick.exe"})

# ê¸°ë³¸ ì„¤ì •
font_path = "C:/Windows/Fonts/HANSomaB.ttf"
WIDTH, HEIGHT = 1080, 1920
PIXABAY_API_KEY = "30559987-df2ee55eeb0cdbaef8ad520a5"
BGM_FOLDER = "C:/music/bgm"

def ensure_folder(path):
    os.makedirs(path, exist_ok=True)

def sanitize_filename(name):
    return re.sub(r'[\\/*?:"<>|]', "", name)

def wrap_text(text, width=30):
    return "\n".join(textwrap.wrap(text, width=width))

def split_sentences(text):
    return [s.strip() for s in re.split(r'[.?!]\s+', text) if s.strip()]

def extract_keyword(sentence):
    return sentence.split()[0] if sentence else "ë°°ê²½"

def download_pixabay_image(search_query, api_key, save_path="default.jpg"):
    base_url = "https://pixabay.com/api/"
    params = {
        "key": api_key,
        "q": search_query,
        "image_type": "photo",
        "orientation": "vertical",
        "safesearch": "true",
        "per_page": 5,
        "lang": "ko"
    }

    response = requests.get(base_url, params=params)
    data = response.json()

    if "hits" in data and len(data["hits"]) > 0:
        image_url = data["hits"][0]["largeImageURL"]
        image_data = requests.get(image_url).content
        with open(save_path, "wb") as f:
            f.write(image_data)
        print(f"âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_path}")
        return save_path
    else:
        print("âŒ ì´ë¯¸ì§€ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

# ğŸ”„ ì´ë¯¸ì§€ ë°°ê²½ íš¨ê³¼
def apply_random_effect(image_clip, duration):
    effect_type = random.choice(["zoom_in", "zoom_out", "pan_left", "pan_right", "static"])
    if effect_type == "zoom_in":
        return image_clip.resize(lambda t: 1 + 0.05 * t).set_duration(duration)
    elif effect_type == "zoom_out":
        return image_clip.resize(lambda t: 1.2 - 0.05 * t).set_duration(duration)
    elif effect_type == "pan_left":
        return image_clip.set_position(lambda t: (-50 + 50 * t / duration, 0)).set_duration(duration)
    elif effect_type == "pan_right":
        return image_clip.set_position(lambda t: (50 - 50 * t / duration, 0)).set_duration(duration)
    else:
        return image_clip.set_duration(duration)

# ğŸ—£ï¸ TTS ìƒì„±
def generate_tts(text, index, voice_gender="male", lang="ko"):
    engine = pyttsx3.init()
    voices = engine.getProperty('voices')
    if voice_gender == "male":
        for v in voices:
            if "male" in v.name.lower() or "ë‚¨ì„±" in v.name:
                engine.setProperty('voice', v.id)
                break
    output_path = f"tts_{index}.wav"
    engine.save_to_file(text, output_path)
    engine.runAndWait()
    return output_path

# ğŸ¬ ìŠ¬ë¼ì´ë“œ ìƒì„±
def create_slide(text, image_path, font_path=font_path, duration=5, index=0):
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"{image_path} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    img_clip_raw = ImageClip(image_path).resize((WIDTH, HEIGHT))
    img_clip = apply_random_effect(img_clip_raw, duration)

    txt = TextClip(
        wrap_text(text),
        fontsize=90,
        font=font_path,
        color='white',
        stroke_color='black',
        stroke_width=3,
        method='caption',
        size=(WIDTH - 200, None),
        align='center'
    ).set_duration(duration)

    bar_height = txt.size[1] + 40
    bar = ColorClip(size=(WIDTH, bar_height), color=(0, 0, 0)).set_opacity(0.0).set_duration(duration)

    txt = txt.set_position(("center", HEIGHT - bar_height - 80))
    bar = bar.set_position(("center", HEIGHT - bar_height - 80))

    # ì˜¤ë””ì˜¤ ì¶”ê°€
    tts_path = generate_tts(text, index)
    audio_clip = AudioFileClip(tts_path)
    video = CompositeVideoClip([img_clip, bar, txt]).set_audio(audio_clip)
    video = video.set_duration(audio_clip.duration)

    return video, tts_path

# ğŸ ì „í™˜ íš¨ê³¼
def apply_transition(prev_clip, next_clip, transition_type):
    if transition_type == "crossfade":
        return prev_clip.crossfadeout(1), next_clip.crossfadein(1)
    elif transition_type == "fadeinout":
        return prev_clip.fadeout(1), next_clip.fadein(1)
    elif transition_type == "slide_right":
        next_slide = next_clip.set_start(prev_clip.duration - 1).set_position(lambda t: ('center', HEIGHT - t * 100))
        return prev_clip, next_slide
    elif transition_type == "slide_bottom":
        next_slide = next_clip.set_start(prev_clip.duration - 1).set_position(lambda t: ('center', HEIGHT + 50 - t * 200))
        return prev_clip, next_slide
    else:
        return prev_clip, next_clip

# ğŸµ ë°°ê²½ìŒì•… ëœë¤ ì„ íƒ
def get_random_bgm():
    if not os.path.exists(BGM_FOLDER):
        return None
    files = [f for f in os.listdir(BGM_FOLDER) if f.lower().endswith(('.mp3', '.wav'))]
    if not files:
        return None
    bgm_path = os.path.join(BGM_FOLDER, random.choice(files))
    print(f"ğŸ¶ ë°°ê²½ìŒì•… ì‚½ì…: {os.path.basename(bgm_path)}")
    return AudioFileClip(bgm_path)

# ğŸ ë©”ì¸
def main():
    input_text = """
    íŠ¸ëŸ¼í”„ ì†Œë…€ê°€ ì‚¬ì¹˜ë¥¼ í•˜ì§€ ì•ŠëŠ”ì´ìœ . íŠ¸ëŸ¼í”„ì˜ ì•„ë“¤ì¸ ë°°ëŸ°ì´ í™©ì œì˜ ì‚¶ì„ ëˆ„ë ¤ì˜¨ ë°˜ë©´ íŠ¸ëŸ¼í”„ ì†Œë…€ì¹´ì´ëŠ” íˆ¬ë°•í•œ ì‚¶ì„ ì‚´ê³  ìˆë‹¤ê³  í•©ë‹ˆë‹¤. ì¹´ì´ëŠ” ë³´í†µ ì¼ë°˜ í•­ê³µí¸ì„ ì´ìš©í•˜ë©° í—ˆìŠ¤íŠ¸ í´ë˜ìŠ¤ë¥¼ ê±°ì˜ íƒ€ì§€ ì•Šê³  í• ì•„ë²„ì§€ì™€ í•¨ê»˜ ì—¬í–‰í•  ë•Œë§Œ ì „ìš©ê¸°ë¥¼ ì´ìš©í•œë‹¤ê³  ë°í˜”ì£ . ì´ë¿ë§Œ ì•„ë‹ˆë¼ ë‚´ìš© í–‰ì‚¬ì— ì°¸ì„í•  ë•ŒëŠ” 59$ ì´ë“¤ì—ìŠ¤ì™€ 245$ í•˜ì´ì˜ ì‹ ìˆ˜ì…ë‹ˆë‹¤. ë°˜ë©´ ë°°ëŸ°ì´ ì–´ë¦´ ì ì˜ ëª©ìš•ì„ ë§ˆì¹œ í›„ ë©œë¼ë‹ˆì•„ëŠ” ê·¸ì˜ ëª¸ì— ìµœê³ ê¸‰ ìºë¹„ì–´ í¬ë¦¼ì„ ë°œë¼ì£¼ê³  í–ˆë‹¤ê³  í•˜ì£ . ë˜í•œ íŠ¸ëŸ¼í”„ íƒ€ì›Œì—ì„œëŠ” í•œì¸µ ì „ì²´ê°€ ë°°ëŸ°ì˜ ì „ìš© ê³µê°„ìœ¼ë¡œ ê¾¸ë©°ì ¸ ìˆì—ˆìœ¼ë©° ê·¸ ê³µê°„ì€ ë§ˆì¹˜ ì™•ì‹¤ì— ê³µì „ì²˜ëŸ¼ í™”ë ¤í•˜ê²Œ ì¥ì‹ë˜ì–´ ìˆì—ˆìŠµë‹ˆë‹¤. ë©œë¼ë‹ˆì•„ëŠ” ë°°ëŸ°ì„ ì²« ë²ˆì§¸ ìƒì†ìë¡œ í‚¤ìš°ê¸° ìœ„í•´ ì—„ê²©í•œ ê¸°ëŒ€ì¹˜ë¥¼ ì„¤ì •í–ˆìœ¼ë©° ê·¸ë¦¬ê³  ì´ë‚´ ë°°ëŸ°ì´ ì¡í˜œì¦ì„ ê°€ì§€ê³  ìˆë‹¤ê³  ì˜¤í•´ë°›ì„ ì •ë„ì˜€ìŠµë‹ˆë‹¤. ë°°ëŸ°ì„ ë³´ë©° ì¹´ì´ëŠ” ë” ììœ ë¡­ê²Œ ì‚¬ëŠ” ê²ƒì„ ì„ íƒí•œ ê²ƒì²˜ëŸ¼ ë³´ì´ì£ .
    """
    sentences = split_sentences(input_text)
    slides = []
    tts_files = []

    for i, sentence in enumerate(sentences):
        keyword = extract_keyword(sentence)
        image_path = f"bg_{i}.jpg"
        result = download_pixabay_image(keyword, PIXABAY_API_KEY, save_path=image_path)
        if result:
            clip, tts_path = create_slide(sentence, image_path, index=i)
            slides.append(clip)
            tts_files.append(tts_path)

    if not slides:
        print("âš ï¸ ì˜ìƒ ìƒì„± ì‹¤íŒ¨: ìŠ¬ë¼ì´ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì „í™˜ íš¨ê³¼ ì ìš©
    final_clips = []
    for i in range(len(slides) - 1):
        transition = random.choice(["crossfade", "fadeinout", "slide_right", "slide_bottom", "none"])
        clip_a, clip_b = apply_transition(slides[i], slides[i + 1], transition)
        final_clips.append(clip_a)
        if transition != "none":
            clip_b = clip_b.set_start(clip_a.end)
        final_clips.append(clip_b)

    if len(slides) == 1:
        final_clips = slides
    elif len(final_clips) < len(slides):
        final_clips.append(slides[-1])

    final_video = concatenate_videoclips(final_clips, method="compose")

    # ğŸ”ˆ ë°°ê²½ìŒì•… ì‚½ì…
    bgm_clip = get_random_bgm()
    if bgm_clip:
        bgm = bgm_clip.volumex(0.3).set_duration(final_video.duration)
        final_video = final_video.set_audio(CompositeAudioClip([final_video.audio, bgm]))

    # ì €ì¥
    save_folder = "C:\\shortsClip"
    ensure_folder(save_folder)
    raw_title = sentences[0][:20] if sentences else "shorts_clip"
    safe_title = sanitize_filename(raw_title)
    output_path = os.path.join(save_folder, f"{safe_title}.mp4")
    final_video.write_videofile(output_path, fps=24)

    # ì •ë¦¬
    for f in tts_files:
        try:
            os.remove(f)
        except Exception as e:
            print(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {f} - {e}")

    del final_video
    gc.collect()

    print(f"ğŸ‰ ì˜ìƒ ì €ì¥ ì™„ë£Œ: {output_path}")

if __name__ == "__main__":
    main()
