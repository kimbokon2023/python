import os
import time
import requests
import re
import textwrap
import random
import gc
from moviepy.editor import (
    TextClip, ImageClip, CompositeVideoClip, ColorClip,
    concatenate_videoclips, AudioFileClip, CompositeAudioClip
)
from moviepy.config import change_settings

# í™˜ê²½ ì„¤ì •
change_settings({"IMAGEMAGICK_BINARY": "C:\\Program Files\\ImageMagick-7.1.1-Q16-HDRI\\magick.exe"})
font_path = "C:/Windows/Fonts/HANSomaB.ttf"
WIDTH, HEIGHT = 1080, 1920
BGM_FOLDER = "C:/music/bgm"
LOAD_IMAGE_FOLDER = "C:/shortsLoadPic"

# ìœ í‹¸
def ensure_folder(path): os.makedirs(path, exist_ok=True)
def sanitize_filename(name): return re.sub(r'[\\/*?:"<>|]', "", name)
def wrap_text(text, width=20): return "\n".join(textwrap.wrap(text, width=width))
def split_sentences(text): return [s.strip() for s in re.split(r'[,.?!]\s+', text) if s.strip()]
def extract_keyword(sentence): return sentence.split()[0] if sentence else "ë°°ê²½"

# Typecast TTS ì„¤ì •
API_TOKEN = "__plt4tj3EcRdrNaiX6vjui6k6Ycz4DQK8ioC3kCsoS5q"
ACTOR_ID = "5ecbbc7399979700087711db"
HEADERS = {
    'Content-Type': 'application/json',
    'Authorization': f'Bearer {API_TOKEN}'
}

def generate_tts_typecast(text, index):
    print(f"TTS ìš”ì²­ ì¤‘ì…ë‹ˆë‹¤... {text[:25]}")
    payload = {
        "actor_id": ACTOR_ID,
        "text": text,
        "lang": "auto",
        "tempo": 1,
        "volume": 100,
        "pitch": 0,
        "xapi_hd": True,
        "max_seconds": 60,
        "model_version": "latest",
        "xapi_audio_format": "wav"
    }

    try:
        response = requests.post("https://typecast.ai/api/speak", headers=HEADERS, json=payload)
        response.raise_for_status()
    except Exception as e:
        print(f"âŒ Typecast ìš”ì²­ ì˜¤ë¥˜: {e}")
        print(f"ì‘ë‹µ: {response.text}")
        raise Exception("TTS ìš”ì²­ ì‹¤íŒ¨")

    result = response.json().get("result", {})
    speak_url = result.get("speak_v2_url")
    if not speak_url:
        raise Exception("TTS ì‘ë‹µ ì˜¤ë¥˜: speak_v2_url ì—†ìŒ")

    for _ in range(60):
        poll = requests.get(speak_url, headers=HEADERS)
        poll_data = poll.json().get("result", {})
        status = poll_data.get("status")
        if status == "done":
            audio_url = poll_data.get("audio_download_url")
            break
        elif status == "fail":
            raise Exception("TTS ìƒì„± ì‹¤íŒ¨")
        time.sleep(1)
    else:
        raise Exception("TTS íƒ€ì„ì•„ì›ƒ")

    if not audio_url:
        raise Exception("TTS ì˜¤ë””ì˜¤ URL ì—†ìŒ")

    output_path = f"tts_{index}.wav"
    audio_response = requests.get(audio_url)
    with open(output_path, "wb") as f:
        f.write(audio_response.content)

    print(f"âœ… TTS ì €ì¥ ì™„ë£Œ: {output_path}")
    return output_path

# ì´ë¯¸ì§€ íš¨ê³¼
def apply_random_effect(image_clip, duration):
    effect_type = random.choice(["zoom_in", "zoom_out", "pan_left", "pan_right", "static"])
    if effect_type == "zoom_in":
        return image_clip.resize(lambda t: 1 + 0.05 * t).set_duration(duration)
    elif effect_type == "zoom_out":
        return image_clip.resize(lambda t: 1.2 - 0.05 * t).set_duration(duration)
    elif effect_type == "pan_left":
        return image_clip.set_position(lambda t: (-50 + 50 * t / duration, 0)).set_duration(duration)
    elif effect_type == "pan_right":
        return image_clip.set_position(lambda t: (50 - 50 * t / duration, 0)).set_duration(duration)
    else:
        return image_clip.set_duration(duration)

# ìŠ¬ë¼ì´ë“œ ìƒì„±
def create_slide(text, image_path, font_path=font_path, duration=4, index=0):
    if not os.path.exists(image_path):
        print(f"âŒ ì´ë¯¸ì§€ ì—†ìŒ: {image_path}")
        return None, None

    img_clip = apply_random_effect(ImageClip(image_path).resize((WIDTH, HEIGHT)), duration)
    txt = TextClip(
        wrap_text(text),
        fontsize=90,
        font=font_path,
        color='white',
        stroke_color='black',
        stroke_width=3,
        method='caption',
        size=(WIDTH - 200, None),
        align='center'
    ).set_duration(duration)

    bar_height = txt.size[1] + 40
    bar = ColorClip((WIDTH, bar_height), color=(0, 0, 0)).set_opacity(0.0).set_duration(duration)
    txt = txt.set_position(("center", HEIGHT - bar_height - 80))
    bar = bar.set_position(("center", HEIGHT - bar_height - 80))

    tts_path = generate_tts_typecast(text, index)
    audio_clip = AudioFileClip(tts_path)

    video = CompositeVideoClip([img_clip, bar, txt]).set_audio(audio_clip).set_duration(audio_clip.duration)
    return video, tts_path

# ì „í™˜ íš¨ê³¼
def apply_transition(prev_clip, next_clip, transition_type):
    if transition_type == "crossfade":
        return prev_clip.crossfadeout(1), next_clip.crossfadein(1)
    elif transition_type == "fadeinout":
        return prev_clip.fadeout(1), next_clip.fadein(1)
    elif transition_type == "slide_right":
        next_slide = next_clip.set_start(prev_clip.duration - 1).set_position(lambda t: ('center', HEIGHT - t * 100))
        return prev_clip, next_slide
    elif transition_type == "slide_bottom":
        next_slide = next_clip.set_start(prev_clip.duration - 1).set_position(lambda t: ('center', HEIGHT + 50 - t * 200))
        return prev_clip, next_slide
    else:
        return prev_clip, next_clip

# ë°°ê²½ìŒì•…
def get_random_bgm():
    if not os.path.exists(BGM_FOLDER): return None
    files = [f for f in os.listdir(BGM_FOLDER) if f.lower().endswith(('.mp3', '.wav'))]
    if not files: return None
    bgm_path = os.path.join(BGM_FOLDER, random.choice(files))
    print(f"ğŸ¶ ë°°ê²½ìŒì•… ì‚½ì…: {os.path.basename(bgm_path)}")
    return AudioFileClip(bgm_path)

# ë©”ì¸ ì‹¤í–‰
def main():
    input_text = """
    íŠ¸ëŸ¼í”„ ë”¸ë“¤ì˜ í›„ëœëœí•œ ê²°í˜¼ ìƒëŒ€.
    ì´ë°©ì¹´ ë‚¨í¸ ì•Œê³  ë³´ë©´ ìœ ëŒ€ê³„ ì¬ë²Œì´ë¼ëŠ” ê±°.
    í•˜ë²„ë“œ ì¶œì‹ ì— ë‰´ìš• ì£¼ê°„ì§€ ì „ ì†Œìœ ì£¼!
    ê·¸ëŸ°ë° ë” ì†Œë¦„ ë‹ëŠ” ê±´ ë‚˜ì´ 24ì‚´ì— ì•„ë²„ì§€ ê¸°ì—… ìƒì†!
    ê·¸ë¦¬ê³  ìˆœìì‚°ì´ ë¬´ë ¤ 1ì¡° 3ì²œì–µ ì› ë„˜ëŠ”ë‹¤ë„¤ìš”!
    ì´ë°©ì¹´ ì•„ë²„ì§€ íŠ¸ëŸ¼í”„ê°€ ê·¸ë¬ë‹¤ì£ .
    ê·¸ëŠ” ì²œì¬ë‹¤ ë‚´ ìµœì•  ì‚¬ìœ„ë‹¤!
    ê·¸ëŸ°ë° ì´ë°©ì¹´ë§Œ ê·¸ëŸ° ì¤„ ì•„ì…¨ì£ ?
    íŠ¸ëŸ¼í”„ì˜ ë‘ ë²ˆì§¸ ë”¸ í‹°íŒŒë‹ˆ íŠ¸ëŸ¼í”„ëŠ”ìš”,
    ë ˆë°”ë…¼ê³„ ì•„í”„ë¦¬ì¹´ ì¬ë²Œì˜ ì•„ë“¤ê³¼ ê²°í˜¼í–ˆì–´ìš”.
    ì²­í˜¼ ë°˜ì§€? ë¬´ë ¤ 18ì–µ ì›ì§œë¦¬ ë‹¤ì´ì•„ëª¬ë“œ!
    ì‹ ë‘ì€ ëŸ°ë˜ëŒ€ ì¡¸ì—… ì•„ë²„ì§€ëŠ” ì„œì•„í”„ë¦¬ì¹´ ë¹„ì¦ˆë‹ˆìŠ¤ ì™•êµ­ì˜ ìˆ˜ì¥!
    ëª¨ë¸ê¸‰ ì™¸ëª¨ì— ì–µë§Œì¥ì ë‚¨í¸ê¹Œì§€?
    íŠ¸ëŸ¼í”„ ë”¸ë“¤ì˜ ê²°í˜¼ ìƒëŒ€ëŠ”.
    ì™•ìë³´ë‹¤ ë” ì™•ìë„¤?
    ì´ì¯¤ ë˜ë©´ ì‚¬ë‘ë„ ìŠ¤í™ì´ë‹¤?
    ì—¬ëŸ¬ë¶„ ìƒê°ì€ ì–´ë– ì„¸ìš”?
    """

    sentences = split_sentences(input_text)
    slides, tts_paths = [], []

    for i, sentence in enumerate(sentences):
        image_path = os.path.join(LOAD_IMAGE_FOLDER, f"{i + 1}.jpg")
        clip, tts_path = create_slide(sentence, image_path, index=i)
        if clip:
            slides.append(clip)
            tts_paths.append(tts_path)

    if not slides:
        print("âš ï¸ ìŠ¬ë¼ì´ë“œ ìƒì„± ì‹¤íŒ¨")
        return

    final_clips = []
    for i in range(len(slides) - 1):
        transition = random.choice(["crossfade", "fadeinout", "slide_right", "slide_bottom", "none"])
        a, b = apply_transition(slides[i], slides[i + 1], transition)
        final_clips.append(a)
        if transition != "none": b = b.set_start(a.end)
        final_clips.append(b)

    if len(slides) == 1:
        final_clips = slides
    elif len(final_clips) < len(slides):
        final_clips.append(slides[-1])

    final_video = concatenate_videoclips(final_clips, method="compose")

    # âœ… ë°°ê²½ìŒì•… + TTS ë¯¹ì‹±
    bgm = get_random_bgm()
    if bgm:
        bgm = bgm.volumex(0.2).set_duration(final_video.duration)
        final_video = final_video.set_audio(CompositeAudioClip([final_video.audio, bgm]))

    save_path = "C:/shortsClip"
    ensure_folder(save_path)
    filename = sanitize_filename(sentences[0][:20]) + ".mp4"
    output = os.path.join(save_path, filename)
    final_video.write_videofile(output, fps=24)

    for f in tts_paths:
        try: os.remove(f)
        except: pass

    print(f"ğŸ‰ ì˜ìƒ ì €ì¥ ì™„ë£Œ: {output}")

if __name__ == "__main__":
    main()
